import aiogram
from aiogram import Bot, Dispatcher, executor, types
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from aiogram.dispatcher import FSMContext

from utils import TestStates
from postgresql import Pstrgsqler
from mongodb import Mongodb
from time import sleep
import asyncio
from redis_file import Redis
import os
import requests
import logging
import speech_recognition as sr
from speech_recognition import Recognizer
from pydub import AudioSegment
import pyttsx3
import soundfile as sf
from config import TOKEN

logging.basicConfig(level=logging.INFO)

bot = Bot(token=TOKEN)

dp = Dispatcher(bot, storage=MemoryStorage())

db = Pstrgsqler()
mng = Mongodb()
r = Redis()

recoq = Recognizer()

AudioSegment.converter = os.getcwd() + "/ffmpeg/bin/ffmpeg.exe"
AudioSegment.ffmpeg = os.getcwd() + "/ffmpeg/bin/ffmpeg.exe"
AudioSegment.ffprobe = os.getcwd() + "/ffmpeg/bin/ffprobe.exe"

# print(sr.Microphone.list_microphone_names())

text_to_speach = pyttsx3.init()
# voices = text_to_speach.getProperty('voices')
# for voice in voices:
#     print('--------------------')
#     print('–ò–º—è: %s' % voice.name)
#     print('ID: %s' % voice.id)


RU_VOICE_ID = "com.apple.speech.synthesis.voice.yuri.premium"
text_to_speach.getProperty('voice')


@dp.message_handler(commands='start')
async def start(message: types.Message):
    mng.add_new_user(message.from_user.id)
    await message.reply('–ü—Ä–∏–≤–µ—Ç, –æ—Ç–ø—Ä–∞–≤—å –≤–æ–π—Å')

    # db.create_words_tab()
    # db.create_unique_user_tab(message.from_user.id)
    # db.create_users_tab()


@dp.message_handler(commands=['addword'])
async def start(message: types.Message):
    await TestStates.add_new_word_state.set()
    await message.answer('–û—Ç–ø—Ä–∞–≤—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ {word}={sentence}={translate}={1-5}')


@dp.message_handler(state=TestStates.add_new_word_state, commands=['stopadd'])
async def stop_add_word(message: types.Message, state: FSMContext):
    await message.answer('–ù–µ –±—É–¥–µ–º –¥–æ–±–∞–≤–ª—è—Ç—å')
    await state.reset_state()


@dp.message_handler(state=TestStates.add_new_word_state, content_types=['text'])
async def add_word(message: types.Message, state: FSMContext):
    obj = message.text
    values = obj.split('=')
    if len(values) == 4:
        mng.adding_word_manually(values)
        await message.answer('–î–æ–±–∞–≤–∏–ª –Ω–æ–≤–æ–µ —Å–ª–æ–≤–æ ' + values[0])
    else:
        await message.answer('–û—à–∏–±–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –≤–≤–æ–¥–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑')
    await state.reset_state()


@dp.message_handler(commands=['startpack'])
async def start_pack(message: types.Message):

    """ –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Å—Ç–µ–π—Ç, –≤–Ω—É—Ç—Ä–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –±—É–¥—É—Ç
        –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å—Å—è –∫–∞–∫ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å.
        –û—Ç–ø—Ä–∞–≤–≤–ª—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å –≤ –ú–æ–Ω–≥—É, –≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –æ—á–µ—Ä–µ–¥—å –∏–∑ —Å–ª–æ–≤
    """

    await TestStates.pack_showing_state.set()
    await message.answer('–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞–∫..')
    user_id = message.from_user.id

    mng.create_queue(user_id)
    que = r.stack_queue(user_id)
    gen = asyncio.create_task(asker(message, que))
    r.del_answers(user_id) # –æ—á–∏—â–∞–µ—Ç —Å—Ç–µ–∫ —Å –æ—Ç–≤–µ—Ç–∞–º–∏, –µ—Å–ª–∏ —Ç–∞–º —á—Ç–æ-—Ç–æ –µ—Å—Ç—å
    await asyncio.gather(gen)


@dp.message_handler(state=TestStates.pack_showing_state, commands=['stoppack'])
async def stop_pack(message: types.Message, state: FSMContext):

    """ –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è –ø–æ–¥–∞—á–∏ —Å–ª–æ–≤ –∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è —Å—Ç–µ–π—Ç–∞ """

    await state.reset_state()
    mng.changing_levels(message.from_user.id)
    await message.answer('–ó–∞–∫–∞–Ω—á–∏–≤–∞–µ–º –ø–∞–∫')


async def asker(message, que):

    """ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å """

    text = f'{que[2]}\n–ü–µ—Ä–µ–≤–æ–¥: {que[3]}'
    await bot.send_message(message.from_user.id, text)


@dp.message_handler(state=TestStates.pack_showing_state, content_types=['text'])
async def loop(message: types.Message, state: FSMContext):

    """ loop —Ä–µ–∞–≥–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞, —Ç–µ–º —Å–∞–º—ã–º –æ–∂–∏–¥–∞—è –æ—Ç–≤–µ—Ç –æ—Ç —é–∑–µ—Ä–∞
        –¥–µ–ª–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –≤–µ—Ä–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞, –∏ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä asker(), –∫–æ—Ç–æ—Ä—ã–π –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å
    """

    ans = message.text
    user_id = message.from_user.id

    que = r.stack_queue(user_id)
    r.check_queue(user_id)

    if ans == que[1]:
        await message.answer('–í–µ—Ä–Ω–æ!')

        # Level: 0. Repeat - No. –£—Ä–æ–≤–µ–Ω—å —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è 6, –ø–æ–∑–∂–µ –ø–µ—Ä–µ–π–¥–µ—Ç –≤ learned
        if que[4] == 0:
            obj = {"word_id": que[0], 'lvl': 6}
            r.add_answer(user_id, obj)

        # Level: 1. Repeat - Yes.
        if que[4] == 1:
            que[4] += 1
            obj = {"word_id": que[0], 'lvl': que[4]}
            r.re_add_word(message.from_user.id, que)

        # Level: 2. Repeat - Yes. –î–æ–±–∞–≤–ª—è—Ç—Å—è –≤ —Å—Ç–µ–∫ —Å–Ω–æ–≤–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è
        elif que[4] == 2:
            que[4] += 1
            obj = {"word_id": que[0], 'lvl': que[4]}
            r.add_answer(user_id, obj)

        # Level: 3-5. Repeat - No. –ï—Å–ª–∏ que[5] True, —Ç–æ —É—Ä–æ–≤–µ–Ω—å –ø–æ–≤—ã—à–∞–µ—Ç—Å—è. False - –æ—Å—Ç–∞—ë—Ç—Å—è –Ω–∞ —Ç–æ–º –∂–µ –º–µ—Å—Ç–µ
        if len(que) > 5:

            if que[5]:
                que[4] += 1
                obj = {"word_id": que[0], 'lvl': que[4]}

            elif not que[5]:
                obj = {"word_id": que[0], 'lvl': que[4]}

            r.add_answer(user_id, obj)

    else:
        await message.answer(f'–ù–µ–≤–µ—Ä–Ω–æ :(\n–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {que[1]}')

        # Level: 0. –î–µ–ª–∞–µ—Ç –ª–≤–ª'–æ–º 1
        if que[4] == 0:
            que[4] += 1

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ 3-5 –ª–≤–ª—ã. –ú–µ—Ç–∫–∞ T/F –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ–ª—å–∫–æ —É —ç—Ç–∏—Ö –ª–≤–ª'–æ–≤
        if len(que) > 5 and que[5]:
            que[5] = False

        r.re_add_word(message.from_user.id, que)

    try:
        que = r.stack_queue(message.from_user.id)
        gen = asyncio.create_task(asker(message, que))
        await asyncio.gather(gen)
    except:
        mng.changing_levels(message.from_user.id)
        await message.answer(f'–ú–æ–ª–æ–¥–µ—Ü! –ü–∞–∫ –∑–∞–∫–æ–Ω—á–µ–Ω!')
        await state.reset_state()


@dp.message_handler(content_types=['voice'])
async def voice_messages_resender(message: types.voice):
    await bot.send_message(message.from_user.id, '–µ—â–µ' + message.voice.file_id)

    print('__________________')
    file_info = bot.get_file(message.from_user.id)
    print(file_info)
    print('__________________')

    print('')
    print('__________________')
    file_path = requests.get(f'https://api.telegram.org/bot{TOKEN}/getFile?file_id={message.voice.file_id}')
    print(file_path)
    print('__________________')

    print('')
    print('__________________')
    file = requests.get(f'https://api.telegram.org/file/bot{TOKEN}/{file_path}')
    print(file)
    print('__________________')

    # data, samplerate = sf.read(file_path)
    # sf.write('template/new_file222222.ogg', data, samplerate)

    # print()
    # print('__________________')
    # print(requests.get(f'https://api.telegram.org/file/bot{TOKEN}/{file_info.file_path}'))
    # print('__________________')

    # file_path = requests.get(f'https://api.telegram.org/bot{TOKEN}/getFile?file_id={message.voice.file_id}').json()['result']['file_path']
    # file = requests.get(f'https://api.telegram.org/file/bot{TOKEN}/{file_path}')

    # data, samplerate = sf.read('template/my_audio.wav')
    # sf.write('new_file.wav', data, samplerate)

    await bot.send_message(message.from_user.id, '–æ –¥–∞')


# def sound_catcher():
#     mic = sr.Microphone(2)
#     with mic as audio_file:
#         print("\n–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 7+3?\n")
#
#         recoq.adjust_for_ambient_noise(audio_file)
#         audio_content = recoq.listen(audio_file)
#
#         print("Converting Speech to Text...")
#
#         try:
#             text = recoq.recognize_google(audio_content, language= 'ru-RU')
#             text = text.split()
#             for i in text:
#                 if i.lower() == num:
#                     print('\n–î–∞, –ø—Ä–∞–≤–∏–ª—å–Ω–æ!\nüéä üéä üéä üéä')
#                     return
#
#             # print("You said: " + text)
#         except:
#             print("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ, –ª–æ—Ö")
#
#
#
# sound_catcher()

# with sample_audio as audio_file:
#     recoq.adjust_for_ambient_noise(audio_file)
#     audio_content = recoq.record(audio_file, duration=7)


if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
